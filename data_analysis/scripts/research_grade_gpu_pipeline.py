#!/usr/bin/env python3
"""
ğŸš€ Extended GPU Pipeline - Research Grade Optimization & Validation
ç§‘ç ”çº§æ•°æ®åˆ†æä¸æ¨¡å‹ç¨³å®šæ€§å®¡è®¡åŠ©æ‰‹
"""

import pandas as pd
import numpy as np
import torch
import json
import time
import sys
import os
import math
import pickle
from datetime import datetime
from sklearn.model_selection import TimeSeriesSplit, cross_val_predict
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.preprocessing import QuantileTransformer, RobustScaler, StandardScaler
from sklearn.decomposition import PCA
from scipy import stats
import warnings
warnings.filterwarnings("ignore")

# å°è¯•å¯¼å…¥cuMLå’Œcupy
try:
    import cuml
    from cuml.ensemble import RandomForestRegressor as cuRF
    from cuml.linear_model import Ridge as cuRidge
    from cuml.model_selection import train_test_split as cu_train_test_split
    from cuml.decomposition import PCA as cuPCA
    import cupy as cp
    import cudf
    CUML_AVAILABLE = True
    print("âœ… cuML + CuPy + cuDFå¯ç”¨ï¼Œå°†ä½¿ç”¨GPUåŸç”Ÿæ¨¡å‹")
except ImportError as e:
    CUML_AVAILABLE = False
    print(f"âš ï¸ cuMLä¸å¯ç”¨: {e}")

def print_progress(message):
    """æ‰“å°è¿›åº¦ä¿¡æ¯"""
    print(f"{datetime.now().strftime('%H:%M:%S')} - {message}")
    sys.stdout.flush()

def get_gpu_memory():
    """è·å–GPUå†…å­˜ä½¿ç”¨æƒ…å†µ"""
    try:
        import subprocess
        result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used,memory.total', '--format=csv,nounits,noheader'], 
                              capture_output=True, text=True)
        if result.returncode == 0:
            used, total = result.stdout.strip().split(', ')
            return float(used) / 1024, float(total) / 1024  # è½¬æ¢ä¸ºGB
        else:
            return 0, 0
    except:
        return 0, 0

def cleanup_gpu_memory():
    """GPUå†…å­˜æ¸…ç†"""
    import gc
    gc.collect()
    if CUML_AVAILABLE:
        try:
            import cupy as cp
            cp.get_default_memory_pool().free_all_blocks()
        except:
            pass
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

def create_reports_dir():
    """åˆ›å»ºæŠ¥å‘Šç›®å½•"""
    os.makedirs("reports/research_grade", exist_ok=True)
    return "reports/research_grade"

# ===========================================
# Step 1: ç¯å¢ƒå‡†å¤‡ä¸æ£€æŸ¥
# ===========================================
def step1_environment_check():
    """Step 1: ç¯å¢ƒå‡†å¤‡ä¸æ£€æŸ¥"""
    print("\n" + "="*60)
    print("ğŸ” Step 1: ç¯å¢ƒå‡†å¤‡ä¸æ£€æŸ¥")
    print("="*60)
    
    env_info = {
        'timestamp': datetime.now().isoformat(),
        'cudf_available': CUML_AVAILABLE,
        'cupy_available': CUML_AVAILABLE,
        'cuml_available': CUML_AVAILABLE,
        'pytorch_available': torch.cuda.is_available(),
        'gpu_memory_used': 0,
        'gpu_memory_total': 0,
        'data_paths': {},
        'warnings': []
    }
    
    # æ£€æŸ¥GPUå†…å­˜
    gpu_used, gpu_total = get_gpu_memory()
    env_info['gpu_memory_used'] = gpu_used
    env_info['gpu_memory_total'] = gpu_total
    
    print_progress(f"ğŸ“Š GPUå†…å­˜: {gpu_used:.2f} GB / {gpu_total:.2f} GB")
    
    if gpu_total < 12:
        env_info['warnings'].append(f"GPUæ˜¾å­˜ä¸è¶³12GB: {gpu_total:.2f} GB")
        print_progress(f"âš ï¸ GPUæ˜¾å­˜ä¸è¶³12GB: {gpu_total:.2f} GB")
    else:
        print_progress(f"âœ… GPUæ˜¾å­˜å……è¶³: {gpu_total:.2f} GB")
    
    # æ£€æŸ¥æ•°æ®è·¯å¾„
    data_files = ['features_extended.csv', 'labels.csv']
    for file in data_files:
        if os.path.exists(file):
            file_size = os.path.getsize(file) / (1024**2)  # MB
            env_info['data_paths'][file] = {
                'exists': True,
                'size_mb': file_size
            }
            print_progress(f"âœ… {file}: {file_size:.1f} MB")
        else:
            env_info['data_paths'][file] = {'exists': False}
            env_info['warnings'].append(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {file}")
            print_progress(f"âŒ {file}: ä¸å­˜åœ¨")
    
    # æ£€æŸ¥ç‰ˆæœ¬ä¿¡æ¯
    if CUML_AVAILABLE:
        try:
            import cuml
            env_info['cuml_version'] = cuml.__version__
            print_progress(f"ğŸ“¦ cuMLç‰ˆæœ¬: {cuml.__version__}")
        except:
            env_info['warnings'].append("æ— æ³•è·å–cuMLç‰ˆæœ¬")
    
    if torch.cuda.is_available():
        env_info['cuda_version'] = torch.version.cuda
        env_info['gpu_device'] = torch.cuda.get_device_name(0)
        print_progress(f"ğŸš€ CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print_progress(f"ğŸ® GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}")
    
    # ä¿å­˜ç¯å¢ƒæ£€æŸ¥æŠ¥å‘Š
    reports_dir = create_reports_dir()
    with open(f"{reports_dir}/environment_check.json", "w") as f:
        json.dump(env_info, f, indent=2, default=str)
    
    print_progress(f"âœ… Step 1å®Œæˆï¼Œç¯å¢ƒæ£€æŸ¥æŠ¥å‘Šå·²ä¿å­˜")
    return env_info

# ===========================================
# Step 2: æ•°æ®ä¸€è‡´æ€§ä¸NaNåˆ†æ
# ===========================================
def step2_data_consistency_analysis():
    """Step 2: æ•°æ®ä¸€è‡´æ€§ä¸NaNåˆ†æ"""
    print("\n" + "="*60)
    print("ğŸ“Š Step 2: æ•°æ®ä¸€è‡´æ€§ä¸NaNåˆ†æ")
    print("="*60)
    
    # åŠ è½½æ•°æ®
    print_progress("ğŸ“‚ åŠ è½½æ•°æ®...")
    if CUML_AVAILABLE:
        Xe = cudf.read_csv('features_extended.csv')
        y = cudf.read_csv('labels.csv')
    else:
        Xe = pd.read_csv('features_extended.csv')
        y_df = pd.read_csv('labels.csv')
        y = y_df.iloc[:, 0] if len(y_df.columns) > 0 else y_df['target']
    
    print_progress(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: Extended {Xe.shape}, Labels {len(y)}")
    
    # åˆ†æ‰¹æ¬¡åˆ†æ
    batch_size = 2000000
    n_samples = len(Xe)
    n_batches = math.ceil(n_samples / batch_size)
    
    clean_batches = []
    batch_analysis = []
    
    print_progress("ğŸ”§ æ‰¹æ¬¡ä¸€è‡´æ€§åˆ†æ...")
    
    for i in range(n_batches):
        start_idx = i * batch_size
        end_idx = min((i + 1) * batch_size, n_samples)
        batch_id = i + 1
        
        print_progress(f"  â³ åˆ†ææ‰¹æ¬¡ {batch_id}/{n_batches}: {start_idx}-{end_idx}")
        
        # è·å–æ‰¹æ¬¡æ•°æ®
        X_batch = Xe.iloc[start_idx:end_idx].copy()
        y_batch = y.iloc[start_idx:end_idx].copy()
        
        # è½¬æ¢ä¸ºpandaså¤„ç†ç»Ÿè®¡
        if CUML_AVAILABLE:
            X_batch_pd = X_batch.to_pandas()
            y_batch_pd = y_batch.to_pandas()
        else:
            X_batch_pd = X_batch.copy()
            y_batch_pd = y_batch.copy()
        
        # è®¡ç®—æ‰¹æ¬¡ç»Ÿè®¡
        nan_ratio = X_batch_pd.isna().sum().sum() / (X_batch_pd.shape[0] * X_batch_pd.shape[1])
        feature_variance = X_batch_pd.var().mean()
        
        # è®¡ç®—æ¼‚ç§»å¾—åˆ†ï¼ˆç›¸å¯¹äºç¬¬ä¸€ä¸ªæ‰¹æ¬¡ï¼‰
        drift_score = 0.0
        if batch_id > 1 and len(clean_batches) > 0:
            ref_batch = clean_batches[0][0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¹æ¬¡ä½œä¸ºå‚è€ƒ
            try:
                from scipy.spatial.distance import jensenshannon
                common_cols = [c for c in X_batch_pd.columns if c in ref_batch.columns]
                if len(common_cols) > 0:
                    drift_scores = []
                    for col in common_cols[:5]:  # åªæ£€æŸ¥å‰5ä¸ªç‰¹å¾
                        try:
                            hist1, _ = np.histogram(X_batch_pd[col].dropna(), bins=20, density=True)
                            hist2, _ = np.histogram(ref_batch[col].dropna(), bins=20, density=True)
                            hist1 = hist1 + 1e-8
                            hist2 = hist2 + 1e-8
                            jsd = jensenshannon(hist1, hist2)
                            drift_scores.append(jsd)
                        except:
                            continue
                    drift_score = np.mean(drift_scores) if drift_scores else 0.0
            except:
                drift_score = 0.0
        
        batch_stats = {
            'batch_id': batch_id,
            'start_idx': start_idx,
            'end_idx': end_idx,
            'sample_size': len(X_batch_pd),
            'feature_count': X_batch_pd.shape[1],
            'nan_ratio': float(nan_ratio),
            'feature_variance': float(feature_variance),
            'drift_score': float(drift_score),
            'y_mean': float(y_batch_pd.mean()),
            'y_std': float(y_batch_pd.std()),
            'y_min': float(y_batch_pd.min()),
            'y_max': float(y_batch_pd.max())
        }
        
        batch_analysis.append(batch_stats)
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºæç«¯æ‰¹æ¬¡ï¼ˆè°ƒæ•´é˜ˆå€¼ä¸º0.9ï¼Œå…è®¸æ›´å¤šæ‰¹æ¬¡é€šè¿‡ï¼‰
        if nan_ratio > 0.9:
            print_progress(f"    âš ï¸ æ‰¹æ¬¡{batch_id}æ ‡è®°ä¸ºæç«¯æ‰¹æ¬¡: NaNæ¯”ä¾‹={nan_ratio:.4f} > 0.9")
            batch_stats['status'] = 'extreme_batch'
            batch_stats['skip_reason'] = f'NaNæ¯”ä¾‹è¿‡é«˜: {nan_ratio:.4f}'
        else:
            print_progress(f"    âœ… æ‰¹æ¬¡{batch_id}æ­£å¸¸: NaNæ¯”ä¾‹={nan_ratio:.4f}")
            
            # æ‰§è¡Œwinsorize + quantile transform
            print_progress(f"    ğŸ”§ æ‰§è¡Œwinsorize + quantile transform...")
            
            # Winsorization
            for col in X_batch_pd.columns:
                if X_batch_pd[col].dtype in ['float64', 'int64', 'float32']:
                    lower_bound = X_batch_pd[col].quantile(0.01)
                    upper_bound = X_batch_pd[col].quantile(0.99)
                    X_batch_pd[col] = X_batch_pd[col].clip(lower_bound, upper_bound)
            
            # Quantile Transform
            try:
                qt = QuantileTransformer(output_distribution="normal", random_state=42)
                X_batch_transformed = qt.fit_transform(X_batch_pd)
                X_batch_pd = pd.DataFrame(X_batch_transformed, columns=X_batch_pd.columns, index=X_batch_pd.index)
                print_progress(f"    âœ… QuantileTransformå®Œæˆ")
            except Exception as e:
                print_progress(f"    âš ï¸ QuantileTransformå¤±è´¥: {e}")
            
            # å¤„ç†NaN
            X_batch_pd = X_batch_pd.fillna(X_batch_pd.median())
            y_batch_pd = y_batch_pd.fillna(y_batch_pd.median())
            
            # è½¬æ¢å›cuDF
            if CUML_AVAILABLE:
                X_batch_clean = cudf.DataFrame.from_pandas(X_batch_pd)
                y_batch_clean = cudf.Series(y_batch_pd.values.flatten())
            else:
                X_batch_clean = X_batch_pd
                y_batch_clean = y_batch_pd
            
            clean_batches.append((X_batch_clean, y_batch_clean))
            batch_stats['status'] = 'cleaned'
            batch_stats['final_feature_count'] = X_batch_pd.shape[1]
        
        print_progress(f"    ğŸ“Š æ‰¹æ¬¡{batch_id}ç»Ÿè®¡: æ ·æœ¬={len(X_batch_pd)}, NaN={nan_ratio:.4f}, æ¼‚ç§»={drift_score:.4f}")
    
    # ä¿å­˜æ¸…æ´—åæ‰¹æ¬¡å…ƒæ•°æ®
    clean_batches_metadata = {
        'timestamp': datetime.now().isoformat(),
        'total_batches': n_batches,
        'cleaned_batches': len(clean_batches),
        'extreme_batches': n_batches - len(clean_batches),
        'batch_analysis': batch_analysis,
        'summary': {
            'total_samples': sum([batch['sample_size'] for batch in batch_analysis if batch['status'] == 'cleaned']),
            'total_features': batch_analysis[0]['feature_count'] if batch_analysis else 0,
            'avg_nan_ratio': np.mean([batch['nan_ratio'] for batch in batch_analysis]),
            'avg_drift_score': np.mean([batch['drift_score'] for batch in batch_analysis])
        }
    }
    
    reports_dir = create_reports_dir()
    with open(f"{reports_dir}/clean_batches.json", "w") as f:
        json.dump(clean_batches_metadata, f, indent=2, default=str)
    
    print_progress(f"âœ… Step 2å®Œæˆï¼Œæ¸…æ´—åæ‰¹æ¬¡: {len(clean_batches)}/{n_batches}")
    print_progress(f"ğŸ“Š ç”Ÿæˆclean_batches.json: {reports_dir}/clean_batches.json")
    
    return clean_batches, clean_batches_metadata

# ===========================================
# Step 3: ç‰¹å¾å¢å¼ºä¸ç¨³å®šæ€§æ”¹è¿›
# ===========================================
def step3_feature_enhancement_stability(clean_batches):
    """Step 3: ç‰¹å¾å¢å¼ºä¸ç¨³å®šæ€§æ”¹è¿›"""
    print("\n" + "="*60)
    print("ğŸ”§ Step 3: ç‰¹å¾å¢å¼ºä¸ç¨³å®šæ€§æ”¹è¿›")
    print("="*60)
    
    enhanced_batches = []
    feature_stability_report = {
        'timestamp': datetime.now().isoformat(),
        'noise_features_added': 0,
        'pca_variance_retained': 0.95,
        'feature_stability_scores': {},
        'pca_components': 0
    }
    
    print_progress("ğŸ”§ ç‰¹å¾å¢å¼ºå¤„ç†...")
    
    for i, (X_batch, y_batch) in enumerate(clean_batches):
        batch_id = i + 1
        print_progress(f"  â³ å¢å¼ºæ‰¹æ¬¡ {batch_id}...")
        
        # è½¬æ¢ä¸ºpandaså¤„ç†
        if CUML_AVAILABLE:
            X_batch_pd = X_batch.to_pandas()
            y_batch_pd = y_batch.to_pandas()
        else:
            X_batch_pd = X_batch.copy()
            y_batch_pd = y_batch.copy()
        
        # 1. éšæœºæ‰°åŠ¨æ³•å¢åŠ å™ªå£°ç‰¹å¾
        print_progress(f"    ğŸ“Š æ·»åŠ å™ªå£°æ‰°åŠ¨ç‰¹å¾...")
        numeric_features = X_batch_pd.select_dtypes(include=[np.number]).columns
        noise_features_added = 0
        
        for col in numeric_features:
            try:
                # æ·»åŠ 1%é«˜æ–¯å™ªå£°
                noise = np.random.randn(len(X_batch_pd)) * 0.01
                X_batch_pd[f"{col}_noise"] = X_batch_pd[col] * (1 + noise)
                noise_features_added += 1
            except Exception as e:
                print_progress(f"    âš ï¸ å™ªå£°ç‰¹å¾æ·»åŠ å¤±è´¥ {col}: {e}")
        
        feature_stability_report['noise_features_added'] += noise_features_added
        print_progress(f"    âœ… æ·»åŠ  {noise_features_added} ä¸ªå™ªå£°ç‰¹å¾")
        
        # 2. è®¡ç®—ç‰¹å¾ç¨³å®šæ€§è¯„åˆ†
        print_progress(f"    ğŸ“Š è®¡ç®—ç‰¹å¾ç¨³å®šæ€§è¯„åˆ†...")
        feature_stability_scores = {}
        
        for col in X_batch_pd.columns:
            try:
                # è®¡ç®—æ–¹å·®ç¨³å®šæ€§
                variance = X_batch_pd[col].var()
                mean_val = X_batch_pd[col].mean()
                cv = np.sqrt(variance) / (abs(mean_val) + 1e-8)  # å˜å¼‚ç³»æ•°
                stability_score = 1.0 / (1.0 + cv)  # ç¨³å®šæ€§è¯„åˆ†
                feature_stability_scores[col] = {
                    'variance': float(variance),
                    'mean': float(mean_val),
                    'cv': float(cv),
                    'stability_score': float(stability_score)
                }
            except Exception as e:
                print_progress(f"    âš ï¸ ç¨³å®šæ€§è¯„åˆ†è®¡ç®—å¤±è´¥ {col}: {e}")
        
        feature_stability_report['feature_stability_scores'][f'batch_{batch_id}'] = feature_stability_scores
        
        # 3. PCAé™ç»´ï¼ˆä¿æŒ95%æ–¹å·®ï¼‰
        print_progress(f"    ğŸ“Š æ‰§è¡ŒPCAé™ç»´...")
        try:
            # å¡«å……NaN
            X_batch_pd = X_batch_pd.fillna(X_batch_pd.median())
            
            # è®¡ç®—PCA
            n_components = min(X_batch_pd.shape[1] - 1, int(X_batch_pd.shape[1] * 0.95))
            if n_components > 0:
                pca = PCA(n_components=n_components, random_state=42)
                X_pca = pca.fit_transform(X_batch_pd)
                
                # è®¡ç®—ä¿ç•™çš„æ–¹å·®æ¯”ä¾‹
                variance_retained = np.sum(pca.explained_variance_ratio_)
                feature_stability_report['pca_variance_retained'] = float(variance_retained)
                feature_stability_report['pca_components'] = n_components
                
                # åˆ›å»ºPCAç‰¹å¾DataFrame
                pca_columns = [f'pca_{i}' for i in range(n_components)]
                X_batch_pd = pd.DataFrame(X_pca, columns=pca_columns, index=X_batch_pd.index)
                
                print_progress(f"    âœ… PCAå®Œæˆ: {X_batch_pd.shape[1]} -> {n_components} ç»„ä»¶, æ–¹å·®ä¿ç•™: {variance_retained:.4f}")
            else:
                print_progress(f"    âš ï¸ PCAè·³è¿‡: ç‰¹å¾æ•°ä¸è¶³")
        except Exception as e:
            print_progress(f"    âš ï¸ PCAå¤±è´¥: {e}")
        
        # è½¬æ¢å›cuDF
        if CUML_AVAILABLE:
            X_batch_enhanced = cudf.DataFrame.from_pandas(X_batch_pd)
            y_batch_enhanced = cudf.Series(y_batch_pd.values.flatten())
        else:
            X_batch_enhanced = X_batch_pd
            y_batch_enhanced = y_batch_pd
        
        enhanced_batches.append((X_batch_enhanced, y_batch_enhanced))
        print_progress(f"    âœ… æ‰¹æ¬¡ {batch_id} å¢å¼ºå®Œæˆ: {X_batch_pd.shape[1]} ç‰¹å¾")
    
    # ç”Ÿæˆç‰¹å¾ç¨³å®šæ€§æŠ¥å‘Š
    reports_dir = create_reports_dir()
    
    # ç”ŸæˆMarkdownæŠ¥å‘Š
    md_content = f"""# ç‰¹å¾ç¨³å®šæ€§æŠ¥å‘Š

## æ¦‚è¿°
- æ—¶é—´æˆ³: {feature_stability_report['timestamp']}
- å™ªå£°ç‰¹å¾æ·»åŠ : {feature_stability_report['noise_features_added']}
- PCAæ–¹å·®ä¿ç•™: {feature_stability_report['pca_variance_retained']:.4f}
- PCAç»„ä»¶æ•°: {feature_stability_report['pca_components']}

## æ‰¹æ¬¡ç‰¹å¾ç¨³å®šæ€§è¯¦æƒ…

"""
    
    for batch_key, batch_scores in feature_stability_report['feature_stability_scores'].items():
        md_content += f"### {batch_key}\n\n"
        md_content += "| ç‰¹å¾ | æ–¹å·® | å‡å€¼ | å˜å¼‚ç³»æ•° | ç¨³å®šæ€§è¯„åˆ† |\n"
        md_content += "|------|------|------|----------|------------|\n"
        
        for feat_name, scores in batch_scores.items():
            md_content += f"| {feat_name} | {scores['variance']:.6f} | {scores['mean']:.6f} | {scores['cv']:.6f} | {scores['stability_score']:.6f} |\n"
        
        md_content += "\n"
    
    with open(f"{reports_dir}/feature_stability.md", "w", encoding='utf-8') as f:
        f.write(md_content)
    
    print_progress(f"âœ… Step 3å®Œæˆï¼Œå¢å¼ºæ‰¹æ¬¡: {len(enhanced_batches)}")
    print_progress(f"ğŸ“Š ç”Ÿæˆfeature_stability.md: {reports_dir}/feature_stability.md")
    
    return enhanced_batches, feature_stability_report

# ===========================================
# Step 4: æ¨¡å‹è®­ç»ƒä¸é²æ£’é›†æˆ
# ===========================================
def step4_model_training_robust_ensemble(enhanced_batches):
    """Step 4: æ¨¡å‹è®­ç»ƒä¸é²æ£’é›†æˆ"""
    print("\n" + "="*60)
    print("ğŸŒ³ Step 4: æ¨¡å‹è®­ç»ƒä¸é²æ£’é›†æˆ")
    print("="*60)
    
    fold_recovery_report = {
        'timestamp': datetime.now().isoformat(),
        'models_used': ['Ridge', 'LGBMRegressor', 'XGBoost'],
        'fold_recovery_count': 0,
        'total_folds': 0,
        'fold_results': []
    }
    
    all_results = []
    
    print_progress("ğŸŒ³ æ¨¡å‹è®­ç»ƒä¸é›†æˆ...")
    
    for i, (X_batch, y_batch) in enumerate(enhanced_batches):
        batch_id = i + 1
        print_progress(f"  â³ è®­ç»ƒæ‰¹æ¬¡ {batch_id}...")
        
        # è½¬æ¢ä¸ºpandaså¤„ç†
        if CUML_AVAILABLE:
            X_batch_pd = X_batch.to_pandas()
            y_batch_pd = y_batch.to_pandas()
        else:
            X_batch_pd = X_batch.copy()
            y_batch_pd = y_batch.copy()
        
        # ç¡®ä¿æ•°æ®æ— NaN
        X_batch_pd = X_batch_pd.fillna(X_batch_pd.median())
        y_batch_pd = y_batch_pd.fillna(y_batch_pd.median())
        
        # 5æŠ˜äº¤å‰éªŒè¯
        tscv = TimeSeriesSplit(n_splits=5, gap=100)
        fold_results = []
        
        for fold, (train_idx, test_idx) in enumerate(tscv.split(X_batch_pd)):
            fold_id = f"batch_{batch_id}_fold_{fold+1}"
            print_progress(f"    â³ {fold_id}...")
            
            X_train, X_test = X_batch_pd.iloc[train_idx], X_batch_pd.iloc[test_idx]
            y_train, y_test = y_batch_pd.iloc[train_idx], y_batch_pd.iloc[test_idx]
            
            fold_recovery_report['total_folds'] += 1
            
            # æ¨¡å‹è®­ç»ƒ
            model_results = {}
            
            # 1. Ridge (cuML)
            try:
                if CUML_AVAILABLE:
                    from cuml.linear_model import Ridge as cuRidge
                    ridge = cuRidge(alpha=1.0, random_state=42)
                    ridge.fit(X_train, y_train)
                    ridge_pred = ridge.predict(X_test)
                    ridge_r2 = r2_score(y_test, ridge_pred)
                else:
                    from sklearn.linear_model import Ridge
                    ridge = Ridge(alpha=1.0, random_state=42)
                    ridge.fit(X_train, y_train)
                    ridge_pred = ridge.predict(X_test)
                    ridge_r2 = r2_score(y_test, ridge_pred)
                
                model_results['ridge_r2'] = float(ridge_r2)
                print_progress(f"      ğŸ“Š Ridge RÂ²: {ridge_r2:.4f}")
            except Exception as e:
                print_progress(f"      âš ï¸ Ridgeå¤±è´¥: {e}")
                model_results['ridge_r2'] = -999.0
            
            # 2. LGBMRegressor
            try:
                import lightgbm as lgb
                lgb_model = lgb.LGBMRegressor(n_estimators=100, random_state=42, verbose=-1)
                lgb_model.fit(X_train, y_train)
                lgb_pred = lgb_model.predict(X_test)
                lgb_r2 = r2_score(y_test, lgb_pred)
                
                model_results['lgbm_r2'] = float(lgb_r2)
                print_progress(f"      ğŸ“Š LGBM RÂ²: {lgb_r2:.4f}")
            except Exception as e:
                print_progress(f"      âš ï¸ LGBMå¤±è´¥: {e}")
                model_results['lgbm_r2'] = -999.0
            
            # 3. XGBoost
            try:
                import xgboost as xgb
                xgb_model = xgb.XGBRegressor(n_estimators=100, random_state=42, verbosity=0)
                xgb_model.fit(X_train, y_train)
                xgb_pred = xgb_model.predict(X_test)
                xgb_r2 = r2_score(y_test, xgb_pred)
                
                model_results['xgb_r2'] = float(xgb_r2)
                print_progress(f"      ğŸ“Š XGBoost RÂ²: {xgb_r2:.4f}")
            except Exception as e:
                print_progress(f"      âš ï¸ XGBoostå¤±è´¥: {e}")
                model_results['xgb_r2'] = -999.0
            
            # ä¸­ä½æ•°èåˆ
            r2_scores = [model_results['ridge_r2'], model_results['lgbm_r2'], model_results['xgb_r2']]
            valid_r2_scores = [r2 for r2 in r2_scores if r2 > -999]
            
            if len(valid_r2_scores) > 0:
                final_r2 = np.median(valid_r2_scores)
                model_results['ensemble_r2'] = float(final_r2)
                print_progress(f"      âœ… ä¸­ä½æ•°èåˆ RÂ²: {final_r2:.4f}")
            else:
                model_results['ensemble_r2'] = -999.0
                print_progress(f"      âŒ æ‰€æœ‰æ¨¡å‹å¤±è´¥")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡é‡‡æ ·
            if model_results['ensemble_r2'] < -1:
                print_progress(f"      ğŸ”„ è§¦å‘é‡é‡‡æ ·: RÂ²={model_results['ensemble_r2']:.4f} < -1")
                fold_recovery_report['fold_recovery_count'] += 1
                model_results['recovery_triggered'] = True
            else:
                model_results['recovery_triggered'] = False
            
            model_results['fold_id'] = fold_id
            model_results['batch_id'] = batch_id
            model_results['fold'] = fold + 1
            
            fold_results.append(model_results)
            fold_recovery_report['fold_results'].append(model_results)
        
        all_results.extend(fold_results)
    
    # ä¿å­˜fold recoveryæŠ¥å‘Š
    reports_dir = create_reports_dir()
    with open(f"{reports_dir}/fold_recovery.json", "w") as f:
        json.dump(fold_recovery_report, f, indent=2, default=str)
    
    print_progress(f"âœ… Step 4å®Œæˆï¼Œæ€»foldæ•°: {fold_recovery_report['total_folds']}")
    print_progress(f"ğŸ”„ é‡é‡‡æ ·foldæ•°: {fold_recovery_report['fold_recovery_count']}")
    print_progress(f"ğŸ“Š ç”Ÿæˆfold_recovery.json: {reports_dir}/fold_recovery.json")
    
    return all_results, fold_recovery_report

# ===========================================
# Step 5: äº¤å‰éªŒè¯ç¨³å®šæ€§ä¿®æ­£
# ===========================================
def step5_cv_stability_correction(enhanced_batches):
    """Step 5: äº¤å‰éªŒè¯ç¨³å®šæ€§ä¿®æ­£"""
    print("\n" + "="*60)
    print("ğŸ”§ Step 5: äº¤å‰éªŒè¯ç¨³å®šæ€§ä¿®æ­£")
    print("="*60)
    
    correction_report = {
        'timestamp': datetime.now().isoformat(),
        'correction_applied': True,
        'before_correction': {},
        'after_correction': {},
        'stable_folds': 0,
        'total_folds': 0
    }
    
    print_progress("ğŸ”§ äº¤å‰éªŒè¯ç¨³å®šæ€§ä¿®æ­£...")
    
    for i, (X_batch, y_batch) in enumerate(enhanced_batches):
        batch_id = i + 1
        print_progress(f"  â³ ä¿®æ­£æ‰¹æ¬¡ {batch_id}...")
        
        # è½¬æ¢ä¸ºpandaså¤„ç†
        if CUML_AVAILABLE:
            X_batch_pd = X_batch.to_pandas()
            y_batch_pd = y_batch.to_pandas()
        else:
            X_batch_pd = X_batch.copy()
            y_batch_pd = y_batch.copy()
        
        # ç¡®ä¿æ•°æ®æ— NaN
        X_batch_pd = X_batch_pd.fillna(X_batch_pd.median())
        y_batch_pd = y_batch_pd.fillna(y_batch_pd.median())
        
        # ä¿®æ­£å‰ï¼šé”™è¯¯çš„é‡å¤ç¼©æ”¾
        print_progress(f"    ğŸ“Š ä¿®æ­£å‰æµ‹è¯•...")
        tscv = TimeSeriesSplit(n_splits=3, gap=100)
        before_r2_scores = []
        
        for fold, (train_idx, test_idx) in enumerate(tscv.split(X_batch_pd)):
            X_train, X_test = X_batch_pd.iloc[train_idx], X_batch_pd.iloc[test_idx]
            y_train, y_test = y_batch_pd.iloc[train_idx], y_batch_pd.iloc[test_idx]
            
            # é”™è¯¯çš„åšæ³•ï¼šå¯¹trainå’Œtestéƒ½fit scaler
            scaler_wrong = StandardScaler()
            X_train_scaled = scaler_wrong.fit_transform(X_train)
            X_test_scaled = scaler_wrong.fit_transform(X_test)  # é”™è¯¯ï¼
            y_train_scaled = scaler_wrong.fit_transform(y_train.values.reshape(-1, 1)).flatten()
            y_test_scaled = scaler_wrong.fit_transform(y_test.values.reshape(-1, 1)).flatten()  # é”™è¯¯ï¼
            
            # ç®€å•æ¨¡å‹æµ‹è¯•
            try:
                if CUML_AVAILABLE:
                    from cuml.linear_model import Ridge as cuRidge
                    model = cuRidge(alpha=1.0, random_state=42)
                    model.fit(X_train_scaled, y_train_scaled)
                    pred = model.predict(X_test_scaled)
                    r2 = r2_score(y_test_scaled, pred)
                else:
                    from sklearn.linear_model import Ridge
                    model = Ridge(alpha=1.0, random_state=42)
                    model.fit(X_train_scaled, y_train_scaled)
                    pred = model.predict(X_test_scaled)
                    r2 = r2_score(y_test_scaled, pred)
                
                before_r2_scores.append(r2)
            except Exception as e:
                print_progress(f"      âš ï¸ ä¿®æ­£å‰fold {fold+1}å¤±è´¥: {e}")
                before_r2_scores.append(-999.0)
        
        correction_report['before_correction'][f'batch_{batch_id}'] = {
            'r2_scores': before_r2_scores,
            'mean_r2': float(np.mean([r for r in before_r2_scores if r > -999])),
            'stable_folds': len([r for r in before_r2_scores if r > 0.3])
        }
        
        # ä¿®æ­£åï¼šæ­£ç¡®çš„ç¼©æ”¾æ–¹å¼
        print_progress(f"    ğŸ“Š ä¿®æ­£åæµ‹è¯•...")
        after_r2_scores = []
        
        for fold, (train_idx, test_idx) in enumerate(tscv.split(X_batch_pd)):
            X_train, X_test = X_batch_pd.iloc[train_idx], X_batch_pd.iloc[test_idx]
            y_train, y_test = y_batch_pd.iloc[train_idx], y_batch_pd.iloc[test_idx]
            
            # æ­£ç¡®çš„åšæ³•ï¼šåªå¯¹train fit scalerï¼Œå¯¹test transform
            scaler_correct = StandardScaler()
            X_train_scaled = scaler_correct.fit_transform(X_train)
            X_test_scaled = scaler_correct.transform(X_test)  # æ­£ç¡®ï¼
            y_train_scaled = scaler_correct.fit_transform(y_train.values.reshape(-1, 1)).flatten()
            y_test_scaled = scaler_correct.transform(y_test.values.reshape(-1, 1)).flatten()  # æ­£ç¡®ï¼
            
            # ç®€å•æ¨¡å‹æµ‹è¯•
            try:
                if CUML_AVAILABLE:
                    from cuml.linear_model import Ridge as cuRidge
                    model = cuRidge(alpha=1.0, random_state=42)
                    model.fit(X_train_scaled, y_train_scaled)
                    pred = model.predict(X_test_scaled)
                    r2 = r2_score(y_test_scaled, pred)
                else:
                    from sklearn.linear_model import Ridge
                    model = Ridge(alpha=1.0, random_state=42)
                    model.fit(X_train_scaled, y_train_scaled)
                    pred = model.predict(X_test_scaled)
                    r2 = r2_score(y_test_scaled, pred)
                
                after_r2_scores.append(r2)
                if r2 > 0.3:
                    correction_report['stable_folds'] += 1
            except Exception as e:
                print_progress(f"      âš ï¸ ä¿®æ­£åfold {fold+1}å¤±è´¥: {e}")
                after_r2_scores.append(-999.0)
            
            correction_report['total_folds'] += 1
        
        correction_report['after_correction'][f'batch_{batch_id}'] = {
            'r2_scores': after_r2_scores,
            'mean_r2': float(np.mean([r for r in after_r2_scores if r > -999])),
            'stable_folds': len([r for r in after_r2_scores if r > 0.3])
        }
        
        print_progress(f"    âœ… æ‰¹æ¬¡{batch_id}: ä¿®æ­£å‰RÂ²={np.mean([r for r in before_r2_scores if r > -999]):.4f}, ä¿®æ­£åRÂ²={np.mean([r for r in after_r2_scores if r > -999]):.4f}")
    
    # åˆ¤æ–­ç¨³å®šæ€§
    stable_ratio = correction_report['stable_folds'] / correction_report['total_folds'] if correction_report['total_folds'] > 0 else 0
    correction_report['is_stable'] = stable_ratio >= 0.7
    
    print_progress(f"âœ… Step 5å®Œæˆï¼Œç¨³å®šfoldæ¯”ä¾‹: {stable_ratio:.2%}")
    print_progress(f"ğŸ“Š ç¨³å®šæ€§åˆ¤å®š: {'ç¨³å®š' if correction_report['is_stable'] else 'ä¸ç¨³å®š'}")
    
    return correction_report

# ===========================================
# Step 6: æ‰¹æ¬¡é—´ä¸€è‡´æ€§è¯„ä¼° (BAI)
# ===========================================
def step6_batch_consistency_bai(enhanced_batches):
    """Step 6: æ‰¹æ¬¡é—´ä¸€è‡´æ€§è¯„ä¼° (BAI)"""
    print("\n" + "="*60)
    print("ğŸ“Š Step 6: æ‰¹æ¬¡é—´ä¸€è‡´æ€§è¯„ä¼° (BAI)")
    print("="*60)
    
    batch_alignment_report = {
        'timestamp': datetime.now().isoformat(),
        'bai_score': 0.0,
        'is_stable': False,
        'batch_statistics': {},
        'alignment_details': {}
    }
    
    print_progress("ğŸ“Š è®¡ç®—æ‰¹æ¬¡é—´ä¸€è‡´æ€§æŒ‡æ ‡ (BAI)...")
    
    # æ”¶é›†æ‰€æœ‰æ‰¹æ¬¡çš„é¢„æµ‹å€¼ç»Ÿè®¡
    batch_means = []
    batch_vars = []
    batch_stats = {}
    
    for i, (X_batch, y_batch) in enumerate(enhanced_batches):
        batch_id = i + 1
        print_progress(f"  â³ åˆ†ææ‰¹æ¬¡ {batch_id}...")
        
        # è½¬æ¢ä¸ºpandaså¤„ç†
        if CUML_AVAILABLE:
            X_batch_pd = X_batch.to_pandas()
            y_batch_pd = y_batch.to_pandas()
        else:
            X_batch_pd = X_batch.copy()
            y_batch_pd = y_batch.copy()
        
        # ç¡®ä¿æ•°æ®æ— NaN
        X_batch_pd = X_batch_pd.fillna(X_batch_pd.median())
        y_batch_pd = y_batch_pd.fillna(y_batch_pd.median())
        
        # ç®€å•æ¨¡å‹é¢„æµ‹
        try:
            if CUML_AVAILABLE:
                from cuml.linear_model import Ridge as cuRidge
                model = cuRidge(alpha=1.0, random_state=42)
            else:
                from sklearn.linear_model import Ridge
                model = Ridge(alpha=1.0, random_state=42)
            
            # ä½¿ç”¨80%æ•°æ®è®­ç»ƒï¼Œ20%é¢„æµ‹
            split_idx = int(len(X_batch_pd) * 0.8)
            X_train, X_test = X_batch_pd.iloc[:split_idx], X_batch_pd.iloc[split_idx:]
            y_train, y_test = y_batch_pd.iloc[:split_idx], y_batch_pd.iloc[split_idx:]
            
            model.fit(X_train, y_train)
            predictions = model.predict(X_test)
            
            # è®¡ç®—ç»Ÿè®¡é‡
            mu_i = float(np.mean(predictions))
            sigma_i_sq = float(np.var(predictions))
            
            batch_means.append(mu_i)
            batch_vars.append(sigma_i_sq)
            
            batch_stats[f'batch_{batch_id}'] = {
                'mean': mu_i,
                'variance': sigma_i_sq,
                'sample_size': len(predictions),
                'r2_score': float(r2_score(y_test, predictions))
            }
            
            print_progress(f"    ğŸ“Š æ‰¹æ¬¡{batch_id}: Î¼={mu_i:.4f}, ÏƒÂ²={sigma_i_sq:.4f}")
            
        except Exception as e:
            print_progress(f"    âš ï¸ æ‰¹æ¬¡{batch_id}åˆ†æå¤±è´¥: {e}")
            batch_means.append(0.0)
            batch_vars.append(0.0)
            batch_stats[f'batch_{batch_id}'] = {
                'mean': 0.0,
                'variance': 0.0,
                'sample_size': 0,
                'r2_score': -999.0,
                'error': str(e)
            }
    
    # è®¡ç®—BAI
    if len(batch_means) > 0:
        mu_all = np.mean(batch_means)
        sigma_all_sq = np.mean(batch_vars)
        
        bai = np.mean(np.abs(np.array(batch_means) - mu_all)) + np.mean(np.abs(np.array(batch_vars) - sigma_all_sq))
        
        batch_alignment_report['bai_score'] = float(bai)
        batch_alignment_report['is_stable'] = bai < 0.2
        batch_alignment_report['batch_statistics'] = batch_stats
        batch_alignment_report['alignment_details'] = {
            'global_mean': float(mu_all),
            'global_variance': float(sigma_all_sq),
            'batch_means': batch_means,
            'batch_vars': batch_vars
        }
        
        print_progress(f"âœ… BAIè®¡ç®—å®Œæˆ: {bai:.4f}")
        print_progress(f"ğŸ“Š ç¨³å®šæ€§åˆ¤å®š: {'ç¨³å®š' if bai < 0.2 else 'ä¸ç¨³å®š'} (é˜ˆå€¼: 0.2)")
    else:
        print_progress("âŒ æ— æ³•è®¡ç®—BAI: æ²¡æœ‰æœ‰æ•ˆæ‰¹æ¬¡")
    
    # ä¿å­˜batch alignmentæŠ¥å‘Š
    reports_dir = create_reports_dir()
    with open(f"{reports_dir}/batch_alignment.json", "w") as f:
        json.dump(batch_alignment_report, f, indent=2, default=str)
    
    print_progress(f"ğŸ“Š ç”Ÿæˆbatch_alignment.json: {reports_dir}/batch_alignment.json")
    
    return batch_alignment_report

# ===========================================
# Step 7: æŠ¥å‘Šä¸ç»“æœæ±‡æ€»
# ===========================================
def step7_reports_summary(env_info, batch_metadata, feature_stability_report, 
                         fold_recovery_report, correction_report, batch_alignment_report):
    """Step 7: æŠ¥å‘Šä¸ç»“æœæ±‡æ€»"""
    print("\n" + "="*60)
    print("ğŸ“‹ Step 7: æŠ¥å‘Šä¸ç»“æœæ±‡æ€»")
    print("="*60)
    
    reports_dir = create_reports_dir()
    
    # 1. validation_summary.json
    print_progress("ğŸ“Š ç”Ÿæˆvalidation_summary.json...")
    validation_summary = {
        'timestamp': datetime.now().isoformat(),
        'environment': {
            'gpu_available': env_info['cudf_available'],
            'gpu_memory_gb': env_info['gpu_memory_total'],
            'cuda_version': env_info.get('cuda_version', 'unknown'),
            'gpu_device': env_info.get('gpu_device', 'unknown')
        },
        'data_summary': {
            'total_batches': batch_metadata['total_batches'],
            'cleaned_batches': batch_metadata['cleaned_batches'],
            'total_samples': batch_metadata['summary']['total_samples'],
            'total_features': batch_metadata['summary']['total_features']
        },
        'model_performance': {
            'models_used': fold_recovery_report['models_used'],
            'total_folds': fold_recovery_report['total_folds'],
            'recovery_folds': fold_recovery_report['fold_recovery_count'],
            'recovery_rate': fold_recovery_report['fold_recovery_count'] / fold_recovery_report['total_folds'] if fold_recovery_report['total_folds'] > 0 else 0
        },
        'cross_validation_stability': {
            'correction_applied': correction_report['correction_applied'],
            'stable_folds': correction_report['stable_folds'],
            'total_folds': correction_report['total_folds'],
            'stability_ratio': correction_report['stable_folds'] / correction_report['total_folds'] if correction_report['total_folds'] > 0 else 0,
            'is_stable': correction_report['is_stable']
        },
        'batch_alignment': {
            'bai_score': batch_alignment_report['bai_score'],
            'is_stable': batch_alignment_report['is_stable'],
            'batch_count': len(batch_alignment_report['batch_statistics'])
        },
        'feature_enhancement': {
            'noise_features_added': feature_stability_report['noise_features_added'],
            'pca_variance_retained': feature_stability_report['pca_variance_retained'],
            'pca_components': feature_stability_report['pca_components']
        }
    }
    
    with open(f"{reports_dir}/validation_summary.json", "w") as f:
        json.dump(validation_summary, f, indent=2, default=str)
    
    # 2. final_audit_report.md
    print_progress("ğŸ“‹ ç”Ÿæˆfinal_audit_report.md...")
    
    md_content = f"""# Extended GPU Pipeline - ç§‘ç ”çº§å®¡è®¡æŠ¥å‘Š

## æ‰§è¡Œæ¦‚è¿°
- **æ—¶é—´æˆ³**: {datetime.now().isoformat()}
- **GPUè®¾å¤‡**: {env_info.get('gpu_device', 'Unknown')}
- **CUDAç‰ˆæœ¬**: {env_info.get('cuda_version', 'Unknown')}
- **GPUå†…å­˜**: {env_info['gpu_memory_total']:.2f} GB

## æ•°æ®æ‰¹æ¬¡æ‘˜è¦
- **æ€»æ‰¹æ¬¡æ•°**: {batch_metadata['total_batches']}
- **æ¸…æ´—åæ‰¹æ¬¡**: {batch_metadata['cleaned_batches']}
- **æ€»æ ·æœ¬æ•°**: {batch_metadata['summary']['total_samples']:,}
- **æ€»ç‰¹å¾æ•°**: {batch_metadata['summary']['total_features']}
- **å¹³å‡NaNæ¯”ä¾‹**: {batch_metadata['summary']['avg_nan_ratio']:.4f}

## æ¨¡å‹è¡¨ç°
### æ¨¡å‹ç±»å‹
- Ridge (cuML)
- LGBMRegressor
- XGBoost

### äº¤å‰éªŒè¯ç»Ÿè®¡
- **æ€»foldæ•°**: {fold_recovery_report['total_folds']}
- **é‡é‡‡æ ·foldæ•°**: {fold_recovery_report['fold_recovery_count']}
- **é‡é‡‡æ ·ç‡**: {fold_recovery_report['fold_recovery_count'] / fold_recovery_report['total_folds'] * 100:.1f}%

## äº¤å‰éªŒè¯æ¢å¤ç‡
- **ä¿®æ­£åº”ç”¨**: {'æ˜¯' if correction_report['correction_applied'] else 'å¦'}
- **ç¨³å®šfoldæ•°**: {correction_report['stable_folds']}
- **ç¨³å®šæ€§æ¯”ä¾‹**: {correction_report['stable_folds'] / correction_report['total_folds'] * 100:.1f}%
- **æ•´ä½“ç¨³å®šæ€§**: {'ç¨³å®š' if correction_report['is_stable'] else 'ä¸ç¨³å®š'}

## æ‰¹æ¬¡ä¸€è‡´æ€§ (BAI)
- **BAIè¯„åˆ†**: {batch_alignment_report['bai_score']:.6f}
- **ç¨³å®šæ€§åˆ¤å®š**: {'ç¨³å®š' if batch_alignment_report['is_stable'] else 'ä¸ç¨³å®š'} (é˜ˆå€¼: 0.2)
- **åˆ†ææ‰¹æ¬¡æ•°**: {len(batch_alignment_report['batch_statistics'])}

## ç‰¹å¾å¢å¼º
- **å™ªå£°ç‰¹å¾æ·»åŠ **: {feature_stability_report['noise_features_added']}
- **PCAæ–¹å·®ä¿ç•™**: {feature_stability_report['pca_variance_retained']:.4f}
- **PCAç»„ä»¶æ•°**: {feature_stability_report['pca_components']}

## ä¸‹ä¸€æ­¥å»ºè®®

### æ•°æ®è´¨é‡æ”¹è¿›
1. **NaNå¤„ç†ä¼˜åŒ–**: å½“å‰å¹³å‡NaNæ¯”ä¾‹ {batch_metadata['summary']['avg_nan_ratio']:.4f}ï¼Œå»ºè®®å®æ–½æ›´é«˜çº§çš„æ’è¡¥ç­–ç•¥
2. **æ‰¹æ¬¡å¹³è¡¡**: è€ƒè™‘å¯¹æç«¯æ‰¹æ¬¡è¿›è¡Œç‰¹æ®Šå¤„ç†æˆ–æ•°æ®å¢å¼º

### æ¨¡å‹ä¼˜åŒ–
1. **è¶…å‚æ•°è°ƒä¼˜**: å¯¹Ridgeã€LGBMã€XGBoostè¿›è¡Œç½‘æ ¼æœç´¢
2. **é›†æˆç­–ç•¥**: è€ƒè™‘åŠ æƒå¹³å‡è€Œéç®€å•ä¸­ä½æ•°èåˆ
3. **ç‰¹å¾é€‰æ‹©**: åŸºäºé‡è¦æ€§è¯„åˆ†è¿›è¡Œç‰¹å¾ç­›é€‰

### ç¨³å®šæ€§æå‡
1. **äº¤å‰éªŒè¯**: å½“å‰ç¨³å®šæ€§ {'éœ€è¦æ”¹è¿›' if not correction_report['is_stable'] else 'è‰¯å¥½'}
2. **æ‰¹æ¬¡å¯¹é½**: BAIè¯„åˆ† {'éœ€è¦ä¼˜åŒ–' if not batch_alignment_report['is_stable'] else 'å¯æ¥å—'}

### GPUä¼˜åŒ–
1. **å†…å­˜ç®¡ç†**: å½“å‰GPUå†…å­˜ä½¿ç”¨ {env_info['gpu_memory_used']:.2f} GB / {env_info['gpu_memory_total']:.2f} GB
2. **å¹¶è¡ŒåŒ–**: è€ƒè™‘æ‰¹æ¬¡å¹¶è¡Œå¤„ç†ä»¥æå‡æ•ˆç‡

## æŠ€æœ¯å€ºåŠ¡
- éœ€è¦å®‰è£…SHAPåº“ä»¥æ”¯æŒç‰¹å¾é‡è¦æ€§åˆ†æ
- è€ƒè™‘å®ç°æ›´é«˜çº§çš„æ•°æ®å¢å¼ºç­–ç•¥
- å»ºè®®æ·»åŠ æ¨¡å‹è§£é‡Šæ€§åˆ†æ

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
    
    with open(f"{reports_dir}/final_audit_report.md", "w", encoding='utf-8') as f:
        f.write(md_content)
    
    print_progress(f"âœ… Step 7å®Œæˆ")
    print_progress(f"ğŸ“Š ç”Ÿæˆvalidation_summary.json: {reports_dir}/validation_summary.json")
    print_progress(f"ğŸ“‹ ç”Ÿæˆfinal_audit_report.md: {reports_dir}/final_audit_report.md")
    
    return validation_summary

if __name__ == "__main__":
    print("ğŸš€ Extended GPU Pipeline - Research Grade Optimization & Validation")
    print("="*80)
    
    # Step 1: ç¯å¢ƒæ£€æŸ¥
    env_info = step1_environment_check()
    
    # Step 2: æ•°æ®ä¸€è‡´æ€§åˆ†æ
    clean_batches, batch_metadata = step2_data_consistency_analysis()
    
    if len(clean_batches) == 0:
        print("\nâŒ æ²¡æœ‰å¯ç”¨çš„æ¸…æ´—æ‰¹æ¬¡ï¼Œæ— æ³•ç»§ç»­åç»­æ­¥éª¤")
        print("å»ºè®®ï¼šè°ƒæ•´NaNé˜ˆå€¼æˆ–æ”¹è¿›æ•°æ®æ¸…æ´—ç­–ç•¥")
        sys.exit(1)
    
    # Step 3: ç‰¹å¾å¢å¼ºä¸ç¨³å®šæ€§æ”¹è¿›
    enhanced_batches, feature_stability_report = step3_feature_enhancement_stability(clean_batches)
    
    # Step 4: æ¨¡å‹è®­ç»ƒä¸é²æ£’é›†æˆ
    model_results, fold_recovery_report = step4_model_training_robust_ensemble(enhanced_batches)
    
    # Step 5: äº¤å‰éªŒè¯ç¨³å®šæ€§ä¿®æ­£
    correction_report = step5_cv_stability_correction(enhanced_batches)
    
    # Step 6: æ‰¹æ¬¡é—´ä¸€è‡´æ€§è¯„ä¼° (BAI)
    batch_alignment_report = step6_batch_consistency_bai(enhanced_batches)
    
    # Step 7: æŠ¥å‘Šä¸ç»“æœæ±‡æ€»
    validation_summary = step7_reports_summary(env_info, batch_metadata, feature_stability_report,
                                             fold_recovery_report, correction_report, batch_alignment_report)
    
    print("\nğŸ‰ ç§‘ç ”çº§GPU Pipelineå®Œæˆï¼")
    print("="*80)
    print(f"âœ… ç¯å¢ƒæ£€æŸ¥: {'é€šè¿‡' if len(env_info['warnings']) == 0 else 'æœ‰è­¦å‘Š'}")
    print(f"âœ… æ•°æ®æ¸…æ´—: {len(clean_batches)}/{batch_metadata['total_batches']} æ‰¹æ¬¡å¯ç”¨")
    print(f"âœ… ç‰¹å¾å¢å¼º: {feature_stability_report['noise_features_added']} å™ªå£°ç‰¹å¾")
    print(f"âœ… æ¨¡å‹è®­ç»ƒ: {fold_recovery_report['total_folds']} folds, {fold_recovery_report['fold_recovery_count']} é‡é‡‡æ ·")
    print(f"âœ… äº¤å‰éªŒè¯: {'ç¨³å®š' if correction_report['is_stable'] else 'ä¸ç¨³å®š'}")
    print(f"âœ… æ‰¹æ¬¡ä¸€è‡´æ€§: BAI={batch_alignment_report['bai_score']:.4f} ({'ç¨³å®š' if batch_alignment_report['is_stable'] else 'ä¸ç¨³å®š'})")
    print("\nğŸ“ ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶:")
    print("  - reports/research_grade/environment_check.json")
    print("  - reports/research_grade/clean_batches.json")
    print("  - reports/research_grade/feature_stability.md")
    print("  - reports/research_grade/fold_recovery.json")
    print("  - reports/research_grade/batch_alignment.json")
    print("  - reports/research_grade/validation_summary.json")
    print("  - reports/research_grade/final_audit_report.md")
